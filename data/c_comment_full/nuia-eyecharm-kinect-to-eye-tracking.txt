If you cannot remember your kickstarter username, please navigate to kickstarter.com and log in. Go to the "Me" section in the upper right corner and then to "My profile". Now you can see your Kickstarter name next to the profile picture. There we go, we posted an update with all details to download the NUIA software.. We are happy to announce, that we will start shipping the NUIA software and SDK! Please visit the update section or check your inbox for further information.. Dear backers, thank you for all your comments! The current process to find a convincing solution for bringing affordable eye tracking to you - in spite of the patent threat the eyeCharm is facing - unfortunately takes longer than we hoped. Please understand that when several parties including lawyers are involved everything has to be rock-solid and more details cannot be disclosed until everything is finalized. However we think that we have found a great solution for all of you and are confident that we can give you an update on the project status and timeline latest until the end of this month. So please bear with us for this time and again our deepest apologies for this delay! Best regards from Munich Tore & Stephan @Alistair Thanks, appreciate that! :) @ Chris eyeCharm will not work with the new Kinect, since it will have a completely differnet housing, camera etc @Michi Currently all NUIA extensions for the apps/games you can see in the video and NUIA Imagine (image organization software) are shipped, however we will add some more in the future and with the NUIA SDK it is really easy to enable your app/game of choice within minutes @Nick Yes, the survey was sent at April 8th.. If you did not receive anything, please send an email to <email> @Patrick, Cliff, Camey: We use the information about your specific diopter to get a bandwith for the development and testing process, rather than to individually configure your software. @Jared: It can work in dark rooms, since the eyeCharm brings its own infrared illumination to actually do the eye tracking. @Arkadiy: The size of the headbox depends a bit on how well you can be tracked. This depends on various factors. In an ideal situation you can use the complete "capture" area of the camera. The hfov of the camera is about 30° and the optimal distance is at about 80 cm + / - 20 cm. With regard to the height, the tilt motor of the Kinect allows adjusting to your seating position. @Omar: We have experimented with both and are trying to support both for the launch so all users can keep their other Kinect installations untouched. One of the opens we are having with supporting both is, that openNI doe not support the tilt control. @Theo: Looking at the usage with the eyeCharm, there is no difference. eyeCharm supports both versions. @Rob: As long as you don't change your pledge, you will keep the place in line. Kickstarter does not really have an option to get two pledges, so the "recommended" way to do multiple pledges in is to create a second Kickstarter account to do the second pledge. If you have international shipping, you can save the shipping cost on every second pledge (just don't add the international shipping fee on the second pledge in Kickstarter) by sending us a mail with the name of the two accounts and the shipping address for both units. @Michi: Direct control of a visible cursor can be activated, but we do not recommend it, so we created another solution. We have tested a visible cursor and the cursor always moving around distracts too much and draws your attention to the cursor. The way we do it: While looking at the screen the NUIA software calculates an "invisible cursor" and only when you hit a key, say "open", look at something for a prolonged time or whatever you prefer to trigger a click, the cursor become a real cursor and executes the click. Because of how the human eye works, precision with all eye tracking systems is limited at about 0.5° as measured from the eye. How many pixels this results in depends on your distance from the monitor and the monitor resolution. In the end this initial precision is not that critical because there are several "tricks" that are handled by the NUIA software to make sure you hit what you are looking for. E.g. instead of using point precision, we use vectors and give NUIA as much awareness of the active areas on the screen as possible to understand what you are aiming for. These are some of the same challenges we had to be solve for our touch screen systems. When touching a screen, people tend to believe they touch with the tip of finger, but the center of gravity of their click is a lot further towards them and changes depending on how they hold the device. @Cybertinus: 1) NUIA is build plattform independent as far as possible. The biggest Windows dependencies we have are the IPC and context management etc. We would be happy to port but it is a question of ressources and demand. If Linux guys want to help us porting, we would even go as far as to setup a joint project and share the relevant source code once the units have shipped (we have done something similar before and had a very good experience). If you know any Linux guys that are interested to support a port and have backed, ask them to send a message via Kickstarter saying "Linux port". 2) Yes, you would need 3. 3 monitors would definitely be an interesting experiment, but we have not done any work in that direction. We would have to evaluate based on the dual monitor technology. 3) The resolution itself is fine. Eye tracking does not work on pixel level anyway. Landscape mode is something we have not tested yet, but since the OS would just report it with the corresponding pixels for width and height there should be no problem for NUIA to detect that. Your setup is definitely a very interesting one and you will definitely need multiple trackers if you want to cover the complete area. How to make sure that the complete screen area in such a setup is trackable will require some fine-tuning. If you want to share details as some kind of best-practice later on, just sent us an KS-mail with your contact data. @RimacV: How to trigger a mouse click depends on the situation. In some situations the action will happen without you having to do a "click" at all. For example if you read through a webpage, the computer will recognize when you get to the bottom edge and scroll automatically. In situations where a "click" is necessary like opening a link or a program in the Windows Menu this can be done either by pressing a key or by a voice command like "open link". In situations, where neither hands nor voice can be used, a long fixation or a visual mouse click button on the screen can be used. Most of the time different ways are available and with the NUIA software we try to make sure that the user does not have to think about it but that it feels natural and is intuitive. @Whitecat: We would love to, but with the Kinect as base device we are limited. A standalone version without the Kinect could be build smaller but would also result in a substantially higher price due to all the additional components that have to be included. We decided to go for an extremely low price point to bring the magic of eye tracking to as many people as possible. @Clement: Except of the white special version, the eyeCharm will be black like the Kinect. Thank you for your support! @Jeremy: In addition to the C++ and C# binding and integration in .Net and Qt, the NUIA SDK comes with a generic C binding that can be used for Python as well as many other languages incl. Matlab, Java, Labview etc @Bar: Sorry that your question about system requirements slipped our attention. Eye tracking algorithms are mathematical calculations based on the image data. E.g. on an Intel Core i5-3470 3,2GHz system NUIA has a peak CPU load of 5%. We are constantly optimizing the algorithms, but to make sure you get a smooth experience, we currently would recommend a PC with Intel or AMD multi-core and at least 2 GB of RAM. @Bar @Wei: The eyeCharm does work with glasses, there are a few challenges however. If you wear bifocal glasses or glasses with IR blocking coating, you won't be able to use the eye tracking functionality. Eye tracking is happening in the infrared spectrum and the IR blocking coating does hide the eyes from the view of the camera. In case of glasses or contact lenses with high diopter there could be tracking issues and you have to decide if you want to give it a try. There is no special value for diopter where it stops working but a combination of various aspects as well as a gradual change in precision. If you experience any problems, we will have a special email address so you can get in touch with us and together we can try to optimize the algorithms to make the eyeCharm work for you. @Logan @Matt: Multi-screens with one screen supported by an eye tracker is already working and is used by our developers. To support each screen with eye tracking, each screen would require one eye tracker. This is because if you turn your head to far to the side (which automatically happens with multiple screens) the camera looses "sight" of your eye - or better: the camera can still see your eyes, but the reflections created by the 2 IR illuminations on both ends of the eyeCharm are not visible anymore and these reflections are necessary to do the eye tracking. Simply using two eyeCharms with two Kinects is not yet supported, by the algorithms. The major challenge here is, that we now could have up to 4 illuminations creating reflections on the eye and we have to create a robust algorithm to make sure we can separate these. There is no show-stopper visible on the way to achieve that, but we will probably not start on that in detail before the devices have been shipped. As a first step, we want to make sure we create the best eye tracking experience possible in the standard scenario. Since many on the team use two monitors, we will be pushing for this. Eyebrows are currently not tracked. We have experimented with conscious winking (which has a longer duration than automatic winking and can be separated) as well as with nodding. In our standard use cases we don't implement it because it did not feel that natural if used repeatedly. Using the SDK it can however be configured easily as an alternative to trigger clicks. @Joseph: Great, thank you for your support. There is no fixed timeline for the other OSs yet, but from all the request we are getting, Mac is definitely in the lead. We are looking forward to creating a solution for your MacBook so you can start using the eyeCharm with it. @Maziar: Once we add support for OS X, we will include the most relevant IDEs (XCode would most probably be one of them). On Windows we currently support deeper SDK integration in Visual Studio and Qt Creator. However basically you can use the IDE of your choice or our NUIA Configuration Creator to develop for NUIA. @Levi: Thanks for the question. We added it to the FAQ - In short: Both versions of Kinect are supported. @edzieba: Thank you for addressing this. It is because of the Kinect's native resolution of 720x480 that we added the special optics to focus the field of view of the IR camera to increase the data available on the eyes of the user. This allows us to do eye tracking in an area of similar size like integrated solutions. The advantage with Kinect is, that its tilt motor makes it easier for the user to adjust to himself on the fly (currently calibrations for the used tilt levels are necessary, but we are working on that). Regarding latency - NUIA was always developed with consumer solutions and applications in mind. We never relied on scientific trackers at high sampling rates, but rather eye trackers at 30 Hz to 60 Hz. For real life applications, the magic is actually in our NUIA middle layer rather than in the tracking precision. Latency, jitter as well as point precision (which is limited in all eye tracking solutions to about 0.5° from the eye because of the specifics of the human view) can be compensated dynamically in different situations by smoothing, vector analysis (rather than point information), backdating etc. This goes beyond the tracking technology to how we as humans act anyway. For example in situations with fast gazes to several points on the screen and key presses to confirm when you focus a point, it is in our nature, to start looking towards the next point before the finger pushes the key all the way down. The computer will thus get the key press event at a time, when the gaze is already travelling to the next point. NUIA compensates for this adjusted to the current usage situation, connected hardware etc in multiple ways. By the way, NUIA does this also for the other modalities next to eye tracking that are supported. Currently Win 7 and 8 are supported, but NUIA is build platform abstracted to be easily ported in the future. Which OS we will start with will depend on the amount of request from different plattforms like Mac OS X, Android, Linux, Chrome OS etc. Currently OS X is in the lead.